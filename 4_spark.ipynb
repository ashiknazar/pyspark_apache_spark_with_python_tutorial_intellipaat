{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- spark uses hadoop  in 2 ways  one is storage,another is cluster management\n",
    "- since spark has its own cluster management computation ,it uses hadoop for storage purposes only\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - apache spark is a lightning fast cluster computing technology ,designed for fast computation.\n",
    " - it is based on hadoop mapreduce ,and extends the mapreduce model to efficiently use it for more tyoes of computations,which includes interactive queries and stream processing.\n",
    " - spark is one of the sub project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- spark helps to run an application in hadoop cluster ,up to 100 times faster in memory ,and 10 times faster when running on disk.\n",
    "- this is possible by reducing no of read/write operations to disk.it stores the intermediate processing of data in memory.\n",
    "- spark has 80 high level operators for interactive querying\n",
    "- advanced analytics : not only supports map reduce ,but also supports sql queries,stream data,ml,graph algorithms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- in memory computation :no need to fetch data from the disk every single time \n",
    "- fault tolerance: through spark abstraction RDD \n",
    "- lazy evaluation:\n",
    "all transformation made in spark rdd involves creation of new rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/sp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/spa.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- spark has modules \n",
    "- each layer has its own data structure\n",
    "- for spark core we have data structure or storage object called RDD (resilient distributed data structure)\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- apache spark core\n",
    "   - spark core is underlying general execution engine fofr spark platform that all other functionality is built upon\n",
    "   - it provides in memory computing and referencing datasets  in external storage system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- spark sql\n",
    "  - is a distributed framework for structured data processing\n",
    "  - using spark sql ,spark gets more information about structure of data and computation\n",
    "  - with this information,spark can perform extra optimization.it uses same execution engine while computing an output.it does not depend on api/language to express the computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- spark streaming\n",
    "   - scalable ,high throughput ,fault tolerant stream processing of live data streams\n",
    "   - spark can access data from kafka,flume,kinesis,or tcp socket\n",
    "   - data received is given to file system,databases,live dashboars.spark uses <b> micro batching </b> for real time streaming\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hadoop vs spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hadoop vs Spark: Key Differences\n",
    "\n",
    "| Feature                 | Hadoop                                | Spark                                 |\n",
    "|-------------------------|---------------------------------------|---------------------------------------|\n",
    "| **Processing Model**     | Batch processing (MapReduce)          | Batch and Stream processing (RDDs, DataFrames, Datasets) |\n",
    "| **Speed**                | Slower due to disk I/O operations     | Faster due to in-memory processing   |\n",
    "| **Data Storage**         | Uses HDFS (Hadoop Distributed File System) | Can use HDFS, S3, or other distributed storage systems |\n",
    "| **Ease of Use**          | Complex to program with MapReduce API | Easier to use with high-level APIs (e.g., DataFrames, Datasets) |\n",
    "| **Fault Tolerance**      | Provides fault tolerance via replication in HDFS | Fault tolerance via RDDs (lineage) and data replication |\n",
    "| **Performance**          | Relatively slow for iterative tasks   | Optimized for iterative operations (e.g., machine learning) |\n",
    "| **Data Processing**      | Processes data in batch mode         | Supports both batch and real-time processing (streaming) |\n",
    "| **Programming Languages**| Java, Python, R, and others via MapReduce | Scala, Python, Java, R |\n",
    "| **Resource Management**  | Uses YARN for resource management    | Can run on YARN, Mesos, or standalone cluster manager |\n",
    "| **Use Cases**            | Large-scale batch processing (e.g., ETL) | Real-time data processing, machine learning, data analytics |\n",
    "| **Learning Curve**       | Steeper, requires knowledge of MapReduce | Easier, more intuitive APIs and better performance for iterative tasks |\n",
    "| **Maturity**             | Older and more established            | Newer, but growing rapidly in popularity |\n",
    "\n",
    "### Summary:\n",
    "- **Hadoop** is a powerful tool for distributed batch processing, but can be slow due to its reliance on disk-based storage (HDFS) and MapReduce.\n",
    "- **Spark** is faster due to its in-memory processing and provides greater flexibility, supporting both batch and real-time processing. It also has more user-friendly APIs and better support for advanced analytics like machine learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### category\n",
    "- hadoop is basic data processing engine\n",
    "    - spark is data analytic engine\n",
    "- hadoop has no in memory computation ,external job scheduler is required\n",
    "    - spark support in memory computation ,no need for external scheduler\n",
    "___ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- using apache spark\n",
    "  - more stability than real time ,stream oriented hadoop frameworks such as twitter storm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "- pyspark is an api written in python that support apache spark\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
